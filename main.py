# -*- coding: utf-8 -*-
"""Image Recognition Text Extraction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FhK2OTeaVe6X2yH9V1tNLt0x-b36NTZV
"""

# !pip install opencv-python
# !pip install imutils
# !pip install blurhash-python
# !pip install numpy --upgrade
# !pip install pytesseract
# !pip install tesseract-ocr

import os 
import numpy as np
import cv2
import imutils
import blurhash
from PIL import Image
import pytesseract
import argparse
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import csv
import nltk
import re
from nltk.tokenize import word_tokenize
from nltk.corpus import wordnet

FILES_DIR = "/content/"

def read_image(input_image):
    try:
        image = cv2.imread(input_image)
    except AttributeError: 
        print(f"Your input file '{input_image}' doesn't seems to be a valid.")
    except:
        print("Unknown error, sorry.")
        
    return image
    
def show_image_opencv(image_instance, name="Bill"):
    try:
        cv2.imshow(name, image_instance)
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    except:
        print("Unknown error, sorry.")

def save_image_opencv(image_instance, target_name=os.path.join(FILES_DIR, "result.jpg")):
    
    try:
        cv2.imwrite(target_name, image_instance)
    except:
        print(f"Unknown error, sorry. Your provided instance: {image_instance} with target: {target_name}")
    

input_image = read_image(os.path.join(FILES_DIR, "/content/cap4.jpeg"))
original_image = input_image.copy()

save_image_opencv(input_image, os.path.join(FILES_DIR, "input_image.png"))

def detect_edges(input_image):
    gray_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)
    gray_image_blured = cv2.blur(gray_image, (3, 3))
    edged_image = cv2.Canny(gray_image_blured, 100, 400, 3)

    return edged_image

edged_image = detect_edges(input_image)

save_image_opencv(edged_image, os.path.join(FILES_DIR, "edged_image2.png"))

def calculate_draw_contours(edged_image, target_image): 
    all_contours = cv2.findContours(edged_image.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    all_contours = imutils.grab_contours(all_contours)
    all_contours = sorted(all_contours, key=cv2.contourArea, reverse=True)[:1]
    contour_perimeter = cv2.arcLength(all_contours[0], True) 
    approximated_poly = cv2.approxPolyDP(all_contours[0], 0.02 * contour_perimeter, True)
    cv2.drawContours(target_image, [approximated_poly], -1, (0,255,0), 2)
    
    return approximated_poly, contour_perimeter


approximated_poly, contour_perimeter = calculate_draw_contours(edged_image, input_image)

save_image_opencv(input_image, os.path.join(FILES_DIR, "contoured_image2.png"))

approximated_poly = approximated_poly.reshape(4, 2)
rectangle = np.zeros((4, 2), dtype="float32")
                
s = np.sum(approximated_poly, axis=1)
rectangle[0] = approximated_poly[np.argmin(s)]
rectangle[2] = approximated_poly[np.argmax(s)]

diff = np.diff(approximated_poly, axis=1)
rectangle[1] = approximated_poly[np.argmin(diff)]
rectangle[3] = approximated_poly[np.argmax(diff)]

(tl, tr, br, bl) = rectangle

def calculate_max_width_height(tl, tr, br, bl):
    width_a = np.sqrt((tl[0] - tr[0])**2 + (tl[1] - tr[1])**2 )
    width_b = np.sqrt((bl[0] - br[0])**2 + (bl[1] - br[1])**2 )
    max_width = max(int(width_a), int(width_b))

    height_a = np.sqrt((tl[0] - bl[0])**2 + (tl[1] - bl[1])**2 )
    height_b = np.sqrt((tr[0] - br[0])**2 + (tr[1] - br[1])**2 )
    max_height = max(int(height_a), int(height_b))
    
    return max_width, max_height

max_width, max_height = calculate_max_width_height(tl, tr, br, bl)

destinations = np.array([
        [0,0],
        [max_width - 1, 0],
        [max_width - 1, max_height - 1],
        [0, max_height - 1]], dtype="float32")

transformation_matrix = cv2.getPerspectiveTransform(rectangle, destinations)

def apply_transformation(image_instance, transformation_matrix, max_width, max_height):
    scan = cv2.warpPerspective(image_instance, transformation_matrix, (max_width, max_height))
    return scan

scanned_image = apply_transformation(original_image, transformation_matrix, max_width, max_height)

save_image_opencv(scanned_image, os.path.join(FILES_DIR, "scanned_image2.png"))

pytesseract.pytesseract.tesseract_cmd = (
    r'/usr/bin/tesseract'
)

image=cv2.imread('/content/scanned_image.png')
image = cv2.resize(image, None, fx=0.6, fy=0.6, interpolation=cv2.INTER_AREA)
gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
threshold_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]
from google.colab.patches import cv2_imshow

cv2_imshow(threshold_img)

text = pytesseract.image_to_string(threshold_img)
print(text)

rm_list = list()

match=re.findall(r'\d+[/.-]\d+[/.-]\d{4}', text)
st=" "
st=st.join(match)
bill_date = st.split(" ")[0]
rm_list.append(bill_date)

nltk.download('punkt',quiet=True)
nltk.download('wordnet',quiet=True)

sent_tokens=nltk.sent_tokenize(text)
store_name = sent_tokens[0].splitlines()[0]
rm_list.append(store_name)

price=re.findall("[0-9]+\.[0-9]+",text)
price = list(map(float,price)) 
bill_amount = max(price)

i=1
address = ''
while True:
  try:
    st = sent_tokens[0].splitlines()[i]
    match=re.findall(r'\d{10}',st)
    if len(match) == 0:
      address += st + ' '
      i+=1
    else:
      break
  except:
    break

store_address = address
rm_list.append(store_address)

nums = text.split("\n")
bill_no = None
check=["Bill Number","Bill No","Bill #","Invoice Number","Invoice No","Invoice #","Token Number","Token No","Token #"]
for i in range(0,len(nums)):
  for s in check:
    if s in nums[i]:
      bill_no = nums[i]
      break
rm_list.append(bill_no)

tokens = word_tokenize(text)

tokenizer = nltk.RegexpTokenizer(r"\w+")
new_words = tokenizer.tokenize(text)
print(new_words)

nltk.download('stopwords')

stop_words = set(nltk.corpus.stopwords.words('english'))

filtered_list=[w for w in new_words if w not in stop_words ]
print(filtered_list)

print("\nStore Name : ",store_name,"\nStore Address : ",store_address,"\nBill Date : ",bill_date,"\nInvoice Number : ",bill_no,"\nTotal Amount : ",bill_amount)